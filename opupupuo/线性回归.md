### 线性回归
回归分析的一种，评估自变量 与因变量 之间是一种线性关系。线性回归可以分为两种：    
+ 简单线性回归：具有一个自变量。
+ 多元线性回归：具有多个自变量。
线性关系的理解：
+ 画出来的图像是直的。
+ 每个自变量的最高次项为1。
-----
###  拟合

拟合，是指构建一种算法（数学函数），使得该算法的计算结果能够与真实数据相吻合。从机器学习角度讲，线性回归就是要构建一个线性函数，使得该函数与目标值之间的相符性最好。从空间的角度来看，就是要让函数的直线（面），尽可能靠近空间中所有的数据点（点到直线的平行于 轴的距离之和最短）。线性回归会输出一个连续值。

-----

### 简单线性回归
-----
#### 模型说明
----
线性回归中，仅有一个自变量时，我们称为**简单线性回归**
$\widehat y = W_0 + W_1 * x$
+ $w_0$ : 截距(偏置)，及bias(b)
+ 这里为了统一，使用$W$ 参数，使用$w_0$ 表示b

#### 损失函数
----
损失函数，简单的说，就是关于误差的一个函
数。损失函数用来衡量模型预测值与真实值之间的差异。机器学习的目标，就是要建立一个损失函数，使得该函数的值最小。
也就是说，损失函数是一个关于模型参数的函数（以模型参数 作为自变量的函数），自变量可能的取值组合通常是无限的，我们的目标，
就是要在众多可能的组合中，找到一组最合适的自变量组合（值），使得损失函数的值最小。

损失函数我们习惯使用 来表示，例如， 则表示以 为自变量的函数。

``` python
import numpy as np
import pandas as pd
# 机器学习库，提供很多有用的机器学习算法。
from sklearn.linear_model import LinearRegression
x = np.arange(0, 100, 0.1)
y = 5 * x - 4
# 将x转换为二维数据，以便在sklearn中使用。
x = x.reshape(len(x), 1)
# 创建线性回归类的对象。
lr = LinearRegression()
# 拟合。根据现有的数据集，建立模型。找出x与y之间的关系（方程式或函数）。
# 注意，fit方法要求的x，必须是二维的x。
lr.fit(x, y)
# 输出权重w1。
print(lr.coef_)
# 输出偏置（截距）w0
print(lr.intercept_)
```
