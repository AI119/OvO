1. **投票分类（Voting Classifier）**：基于多数表决或概率平均的投票分类方法。可以使用硬投票（多数表决）或软投票（概率平均）来集成基分类器的预测结果。
    
2. **随机森林（Random Forest）**：通过构建多个决策树并将它们的预测结果进行平均来进行集成。随机森林采用了决策树的平均方法，并通过引入随机特征选择和样本采样来增加模型的多样性。
    
3. **梯度提升树（Gradient Boosting Trees）**：通过迭代地训练多个决策树，每一步都在之前模型的残差上构建新的决策树。最终的预测结果是基于所有决策树的加权平均。
    
4. **Bagging**：通过自助采样（bootstrap sampling）构建多个独立的基学习器，并将它们的预测结果进行平均。Bagging 可以用于各种基学习算法，如 BaggingRegressor 和 BaggingClassifier。
    
5. **平均回归（Averaging Regression）**：在回归问题中，可以通过平均多个回归模型的预测结果来进行集成。例如，平均岭回归（Ridge Regression）、平均 Lasso 回归（Lasso Regression）等。
    
6. **模型堆叠（Model Stacking）**：模型堆叠是一种更复杂的集成方法，它将多个基学习器的预测结果作为输入，再通过另一个元学习器（称为"元模型"）来融合这些预测结果。元模型可以是线性模型、决策树、神经网络等。