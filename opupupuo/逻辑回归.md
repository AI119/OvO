逻辑回归是一个分类算法，作用是可以将样本划分为不同的类别。根据样本不同的特征，得出每个样本是哪一类的数据。

#### 初步尝试
对于逻辑回归，可以考虑使用线性回归的建模方式。
![[Pasted image 20230517104228.png]]
通过线性回归得出一个结果z，但是通过这种方式得出的结果是一个连续的值，我们可以通过将阈值设置为某一个值，当结果大于这个值时，模型将样本判定为一个类别，当结果小于等于这个值时，将模型判定为另外一个类别。这样，模型就实现了一个二分类的任务。
假设真实类别 的值为1与0则模型的预测结果 为：
![[Pasted image 20230517104359.png]]

## sigmoid函数
**函数原型**
对于分类任务来说，如果仅仅给出分类的结果，这些信息可能是不充分的。如果在分类的同时，也能够提供样本属于该 类别的概率，这在现实中是非常实用的。例如，某人患病的概率，明天下雨的概率等。 因此，我们需要将 的值转换为概率值，逻辑回归使用sigmoid函数来实现转换，该函数的原型为：
$$\sigma\left(z\right)=\frac1{1+e^{-2}}$$
![[Pasted image 20230528161504.png]]

或者是
$$
\hat{y} = 
\begin{cases}
1, & {\sigma(z) > 0.5} \\
0, & {\sigma(z) <= 0.5}
\end{cases}
$$

## [[逻辑回归推导过程]]

## [[逻辑回归实例]]

## [[结果可视化]]

## [[计算概率值]]
作为分类模型，不仅能够预测样本所属的类别，而且，还可以预测属于各个类别的概率，这在实践中是 非常有意义的。

## [[绘制决策边界]]


# 模型评估
## 混淆矩阵
混淆矩阵，可以用来评估模型分类的正确性。该矩阵是一个方阵，矩阵的数值用来表示模型预测结果与 真实结果的对比统计，包括真正例（True Positive），假正例（False Positive），真负例（True Negative），假负例（False Negative）。

| | | | **预测值** |
|:---|:---:|:---:|----:|
| || 负例| 正例|
|**实际值**|负例 |真负例（TN）| 假正例（FP）|
| |正例 | 假负例（FN）| 真正例（TP）|
## [[评估指标]]
### ROC与AUC
1、[[ROC曲线]]

$$ FPR = \frac{FP}{FP + TN} $$
$$TPR = \frac{TP}{TP + FN} $$
2、AUC
- AUC（Area Under the Curve）是指ROC曲线下的面积，在比较多个分类模型效果时，会比ROC曲线非常直观。

3、[[ROC曲线绘制]]

4、[[PR曲线]]
精准率与召回率无法同时增大，一个增大时，另外一个可能就会降低。
	- 可能降低，不表示一定会降低。
	- 也可能保持不变。
- 随着召回率的增加，精准率一定会呈现下降的趋势。
- 当对精准率或召回率具有定量要求时，P-R曲线就会非常有用

5、评估指标的应用场景
混淆矩阵：提供分类模型性能的详细视图，需要直观识别特定类型的错误。
- 正确率：样本分布均衡，且所有类别的错误分类成本大致相等。
	- 人的性别分类。
	- 颜色分类。
- 精准率：负例预测为正例（假正例）的代价很大。
	- 垃圾邮件检测。
	- 投资时机预测。
- 召回率：正例预测为负例（假负例）的代价很大。
	- 新冠阳性检测。
	- 逃犯识别。
- F1值：训练样本中类别分布不均匀或误报（假正例）和漏报（假负例）的代价不同。
	- 精准率与召回率的适用场景。
- ROC（AUC）：比较不同分类器的性能和选择最佳分类阈值。
	- 两个（或多个）模型谁的分类效果更好。