# 线性回归类
用于拟合线性回归模型并对数据进行预测，可以处理单变量和多变量的数据
``` python
#线性回归类，用于拟合线性回归模型并对数据进行预测，可以处理单变量和多变量的数据
from sklearn.linear_model import LinearRegression
```
  
该类的功能是实现一个简单的线性回归模型，可用于预测一个连续型的响应变量（或因变量）和一个或多个自变量之间的关系。具体来说，该模型可以拟合形如 $y = \beta_0 + \beta_1 x_1 + ... + \beta_n x_n$ 的线性方程，其中 $y$ 是响应变量，$x_1, ..., x_n$ 是自变量，$\beta_0, \beta_1, ..., \beta_n$ 是回归系数，该模型可以预测响应变量 $y$ 的值。在模型拟合完成之后，可以使用该模型进行预测，计算模型的性能指标，如均方误差等，或者进行特征选择等。 Scikit-learn 提供了许多其他的机器学习模型和工具，可以用于分类、聚类、降维等任务。
    该类包含以下两种属性

``` python
#该类包含两个属性
lr.coef_ #训练后的模型的系数，也就是x的权重。如果模型有多个特征，则返回一个数组，每个元素对应一个特征的系数。

lr.intercept_ #训练好的模型的截距
```

# 切分数据集
    用于切分数据的函数：`from sklearn.model_selection import train_test_split` 
``` python
#这个函数用来切分数据集，将需要切分的数据按照顺序输入进去
"""
test_size=0.3   这个参数用来控制切分的比例，0.3意思为留下30%的测试集

shuffle:用来指定是否进行随机洗牌操作，默认值为True
random_state:随机种子。用来控制(固定)随机行为。随机种子相同，洗牌的时候，顺序就相同
"""
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```


#  用于评估模型的函数：

`from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score`
    
1、`mean_squared_error` 均方误差：指预测值和真实值之间差值的平方的平均值。均方差越小，表示预测值与真实值之间的差异越小，模型的性能越好
    
 ```python
    from sklearn.metrics import mean_squared_error
    mse = mean_squared_error(y_true, y_pred)
    ```
    
这种评估适合少量的数据，当数据量增大时，这种评估方式会被大量的数据所影响，从而导致评估结果出现误差。
    
2、`mean_absolute_error` 平均绝对误差：平均绝对误差是预测值和真实值之间差值的绝对值的平均值。与均方误差相比，平均绝对误差更加关注预测值与真实值之间的实际差异。
    
```python
    from sklearn.metrics import mean_absolute_error
    mae = mean_absolute_error(y_true, y_pred)
    ```
    
3、`r2_score` 决定系数：衡量模型拟合效果的指标，其值介于0和1之间，越接近1表示模型的预测效果越好。

 ``` python
    from sklearn.metrics import r2_score
	r2 = r2_score(y_true, y_pred)
```
----
# 用于保存模块的类

  当我们训练好模型后，就可以使用模型进行预测。然而，这毕竟不像打印一个Hello World那样简单，当我们需要的时候，重新运行一次就可以了。在实际 生产环境中，数据集可能非常庞大，如果在我们每次需要使用该模型时，都去重新运行程序去训练模型，势必会耗费大量的时间。 为了方便以后能够复用，我们可以将模型保存，在需要的时候，直接加载之前保存的模型，就可以直接进行预测。其实，保存模型，就是保存模型的参数 （结构），在载入模型的时候，将参数（结构）恢复成模型保存时的参数（结构）而已。

##### 保存模型

``` python
# 糖尿病数据集。 
from sklearn.datasets import load_diabetes import joblib 
# return_X_y：返回X与y，而不是返回数据对象。 
X, y = load_diabetes(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) lr = LinearRegression() lr.fit(X_train, y_train) print(lr.coef_, lr.intercept_) 
# 对模型进行保存。(模型保存的目录必须事先存在，否则会产生错误。) 
joblib.dump(lr, "lr.model")
```

##### 载入模型
``` python
# 恢复保存的模型
model = joblib.load("lr.model")
print(type(model))
print(model.coef_, model.intercept_)
y_hat = model.predict(X_test)
print(y_hat[:10])
```

# 用于多项式回归的类
  多项式回归是一种在线性回归的基础上引入多项式特征的扩展模型。在多项式回归中，通过添加自变量的高次项，可以拟合出非线性的关系。
  ``` python
  from sklearn.preprocessing import PolynomialFeatures
```

使用方式如下：
``` python
# 创建多项式特征对象 
poly_features = PolynomialFeatures(degree=2) # 选择二阶多项式回归模型 
# 进行多项式特征扩展 
X_poly = poly_features.fit_transform(X) # 将特征矩阵转换为包含原始特征和多项式特征的新特征矩阵
```

## [[流水线]]
`from sklearn.pipeline import Pipeline` 引入流水线。
流水线具有最后一个评估器的所有方法。当通过流水线对象调用方法$f$时，会执行这样的过程（假设流水线具有$n$个评估器）：
  + 如果$f$是fit或fit_transform方法，则会首先对前$n-1$个评估器依次调用fit_transform方法，然后再最后一个评估器上调用$f$方法。
  + 如果$f$是其他方法，则会首先对前$n-1$个评估器依次调用transform方法，然后在最后一个评估器上调用$f$方法