 梯度下降适用于数据量较大的数据集。有以下几种梯度下降的方式

### 随机梯度下降

优点：
+ 更新速度较快。
+ 适合大型数据集
+ 可能会越过局部最小值，得到全局最优解。
缺点：
+ 更新方向上不够稳定。
+ 学习率($\eta$)调整较为困难。

### 批量梯度下降

优点：
+ 更新方向稳定
+ 可以并行化计算梯度
缺点：
+ 更新速度较慢
+ 不适合大型数据集
+ 容易陷入局部最小值

### 小批量梯度下降

优点：
+ 更新方向稳定。
	+ 更新速度适中。
	+ 更新方向稳定性适中
	+ 可以在一定程度上并行化计算梯度
缺点：
+ 需要实现治党批次的样本数量