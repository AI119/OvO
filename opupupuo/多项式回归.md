我们可以使用线性回归模型来拟合数据，然而，在现实中，数据未必总是线性（或接近线性）的。当数据并非线性 时，直接使用LinearRegression的效果可能会较差，产生欠拟合。[[欠拟合与过拟合]]

多项式回归是一种在线性回归的基础上引入多项式特征的扩展模型。在多项式回归中，通过添加自变量的高次项，可以拟合出非线性的关系。

线性回归模型的形式是 $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \epsilon$，其中 $y$ 是响应变量，$x_1, x_2, ..., x_n$ 是自变量，$\beta_0, \beta_1, \beta_2, ..., \beta_n$ 是回归系数，$\epsilon$ 是误差项。

在多项式回归中，我们将自变量 $x$ 的高次项引入模型，形成如下的多项式方程：

$y = \beta_0 + \beta_1 x + \beta_2 x^2 + ... + \beta_d x^d + \epsilon$

其中，$d$ 是多项式的阶数，表示引入的最高次项。通过引入高次项，模型可以更好地拟合数据中的非线性关系。

例如，对于一个一元多项式回归模型（只有一个自变量 $x$），如果选择二阶多项式（$d=2$），则模型可以表示为：

$y = \beta_0 + \beta_1 x + \beta_2 x^2 + \epsilon$

这个模型将会拟合一个二次曲线，可以更好地适应数据中的非线性关系。

多项式回归可以通过将*自变量的高次幂*作为新的特征加入到线性回归模型中来实现。在实践中，可以使用特征变换或者多项式特征扩展的方法，将原始自变量转换为多项式特征。然后使用线性回归模型进行拟合和预测。

多项式回归的一个重要注意事项是需要根据数据和问题的特点选择合适的多项式阶数。过高的阶数可能导致[[过拟合]]，而过低的阶数可能无法很好地拟合数据中的非线性关系。因此，在应用中需要进行模型评估和选择最佳的多项式阶数。

----

## 多项式扩展规则
多项式特征扩展是一种将原始特征矩阵转换为包含原始特征及其交互项和高次项的新特征矩阵的方法。它的规则如下：

给定一个原始的特征矩阵，假设有 `n` 个特征和 `m` 个样本。多项式特征扩展将每个样本的特征按照指定的多项式阶数进行组合，并生成包含所有可能的交互项和高次项的新特征矩阵。

具体而言，假设原始特征矩阵为 X，其形状为 `(m, n)`，其中每一行代表一个样本，每一列代表一个特征。多项式特征扩展的规则如下：

1. 对于每个样本，将原始特征按照指定的多项式阶数进行组合，生成包含原始特征及其所有可能的交互项和高次项的新特征。
2. 对于每个特征组合，计算它们的乘积或幂次。
3. 组合方式可以包括一次项（原始特征本身）、交互项（两个特征的乘积）和高次项（一个特征的多次幂）。
4. 最终生成的新特征矩阵的列数取决于特征的组合方式和多项式阶数。

举例说明：

假设原始特征矩阵 X 有两个特征 `[x1, x2]`，且多项式阶数为 2。按照多项式扩展规则，生成的新特征矩阵的列包括：

- 一次项：`[1, x1, x2]`
- 交互项：`[x1*x1, x1*x2, x2*x2]`
- 二次项：`[x1^2, x2^2]`

因此，最终生成的新特征矩阵的列数为 1 + 2 + 2 = 5。

多项式特征扩展可以通过 `PolynomialFeatures` 类实现，在 Scikit-learn 中提供了方便的功能。通过指定多项式阶数，`PolynomialFeatures` 类会自动按照上述规则对特征矩阵进行扩展。

------
[[多项式回归方法]]
[[多项式回归实例]]